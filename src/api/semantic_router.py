from sentence_transformers import SentenceTransformer, util
import torch
import joblib
import os

# Setup paths relative to this file
BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
ANCHORS_PATH = os.path.join(BASE_DIR, 'models', 'semantic_anchors.pkl')

print("Loading Semantic Brain...")
# Load the model once at startup
semantic_model = SentenceTransformer('all-MiniLM-L6-v2')

# Load the anchors generated by your training script
CONCEPT_VECTORS = {}
if os.path.exists(ANCHORS_PATH):
    print(f"   -> Loading anchors from {ANCHORS_PATH}...")
    CONCEPT_VECTORS = joblib.load(ANCHORS_PATH)
else:
    print("WARNING: semantic_anchors.pkl not found. Run train_model.py first.")

def check_semantic_match(text, threshold=0.35): 
    """
    Compares input text against the data-driven anchors.
    """
    if not CONCEPT_VECTORS:
        return None

    input_vec = semantic_model.encode(text, convert_to_tensor=True)
    
    best_score = 0
    best_category = None
    
    # Check against every risk category
    for category, anchor_tensor in CONCEPT_VECTORS.items():
        # Calculate similarity against all 25 examples for this category
        cosine_scores = util.cos_sim(input_vec, anchor_tensor)
        
        # Find the highest match in this category
        max_score_in_category = torch.max(cosine_scores).item()
        
        if max_score_in_category > best_score:
            best_score = max_score_in_category
            best_category = category
            
    # Logic: Only flag if it's a strong match
    if best_score > threshold:
        # Boost confidence slightly for UX
        final_confidence = min(0.99, best_score + 0.15)
        
        return {
            "category": best_category,
            "confidence": round(final_confidence, 2), 
            "description": f"AI identified concepts matching '{best_category}' clauses found in the CUAD commercial dataset."
        }
    
    return None